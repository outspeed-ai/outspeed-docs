---
title: "Outspeed API"
description: "Embed low-latency voice interaction in your apps with Outspeed API"
---

The Outspeed API enables you to build fast, natural voice experiences by connecting to our hosted speech-to-speech stack.

With Outspeed, you can send and receive both text and audio in real time, leverage voice activity detection, call external functions, and more.

<Note>
  Outspeed API is fully compatible with the OpenAI Realtime API.
</Note>

## How It Works

Outspeed API is event-driven. After connecting via WebRTC, your app sends [Client Events](/api-spec/client) 
and listens for [Server Events](/api-spec/server) to drive the conversation.

Getting started is easy:

- Install the [JS SDK](https://www.npmjs.com/package/@outspeed/client)
- Install the [React SDK](https://www.npmjs.com/package/@outspeed/react)
- Install the [Swift SDK](https://github.com/outspeed-ai/OutspeedSwift)

Each SDK manages the WebRTC connection and event flow for you, so you can focus on building your app.

## Key Capabilities

- **Text & Audio**: Send and receive both text and audio
- **Realtime Responses**: Low-latency replies for natural conversations
- **Function Calling**: Call external tools and services

## API Events

The API is organized around events:

<CardGroup>
  <Card
    title="Client Events"
    icon="arrow-up-right-from-square"
    href="/api-spec/client"
  >
    Events your app can send to the Realtime server.
  </Card>
  <Card
    title="Server Events"
    icon="arrow-down-left-from-square"
    href="/api-spec/server"
  >
    Events your app receives from the Realtime server.
  </Card>
</CardGroup>
