---
title: "Live Sports Commentator"
description: "A realtime commentator that provides live commentary on sports events."
---

<Info>
  Make sure you have gone over [QuickStart](/examples/quickstart) before trying
  this example.
</Info>

In this example, we will build a realtime commentator that provides commentary on a live poker tournament.
We accomplish by using screenshare to capture the live game on Youtube and microphone audio to interact with the commentator.

## Demo

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/WJaYLcX1o7E?si=hNvJwHWbNAXQCsck"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  referrerpolicy="strict-origin-when-cross-origin"
  allowfullscreen
></iframe>

## **Creating a Poker Commentator in 3 steps**

This app will process input from your microphone, video from screenshare, send it to an LLM and convert the reponse back to voice.

- The full github repository is available [here.](https://github.com/xAlpha8/realtime-examples)

<Info>
  This application will initially support only English as the source language.
</Info>

<Steps>
  <Step title="Start by cloning the repository">
    <CodeGroup>
    ```bash MacOS/Linux
    git clone https://github.com/xAlpha8/realtime-examples.git
    cd realtime-examples/
    ```

    ```bash Windows
    git clone https://github.com/xAlpha8/realtime-examples.git
    cd realtime-examples/
    ```
    </CodeGroup>

    <CodeGroup>
    ```bash MacOS/Linux
    python3 -m venv .venv
    source .venv/bin/activate
    pip install realtime-client
    ```

    ```bash Windows
    python -m venv .venv
    .venv\Scripts\activate
    pip install realtime-client
    ```
    </CodeGroup>

  </Step>
  <Step title="Deploy to Realtime">
    <Warning>Ensure you're in the same directory as poker_commentator.py!</Warning>
    We will use our realtime [Python SDK](/python_client) to deploy our application.

    <CodeGroup>
    ```bash MacOS/Linux
    cd ./multimodal_ai_demos/backend/
    realtime deploy --api-key=<your-api-key> poker_commentator.py
    ```

    ```bash Windows
    cd .\multimodal_ai_demos\backend\
    realtime deploy --api-key=<your-api-key> poker_commentator.py
    ```
    </CodeGroup>

    Your build will complete in seconds, and then you'll receive a link to your deployed function on the Realtime server. Copy the link.

    (Coming soon) You can also go to your app on the [Realtime dashboard](https://www.getadapt.ai/dashboard) and get the link.

  </Step>
  <Step title="Launch the frontend">
    We have already created a simple frontend using our [React SDK](/javascript).

    Change directory to the frontend directory.

    <CodeGroup>
    ```bash MacOS/Linux
    cd ../frontend/
    ```

    ```bash Windows
    cd ..\frontend\
    ```
    </CodeGroup>

    Install the dependencies and run the frontend.
    <CodeGroup>
    ```bash MacOS/Linux
    npm install
    npm run dev
    ```

    ```bash Windows
    npm install
    npm run dev
    ```
    </CodeGroup>

    This will launch a simple frontend to interact with the backend.
    You can then browse to the following page with your browser:

    http://127.0.0.1:5173

    Click on the settings icon and select the appropriate audio and video device.
    In the functionURL field, enter the link of your deployed function.
    Click and enable the `Enable Screen Share` checkbox to share your screen.
    Close the settings menu and click `Start`.
    Select the appropriate browser tab to share your screen.

  </Step>
</Steps>

## **Understanding the Process**

Review the code in `poker_commentator.py`.

#### **Setup**

The `PokerCommentator` class initializes with the `setup` method, which is automatically called when the application starts. This method is responsible for setting up the necessary services and loading models. Here's a breakdown of the services initialized:

- **DeepgramSTT**: Converts spoken audio to text using Deepgram's speech-to-text API, configured with a sample rate of 8000 Hz.
- **KeyFrameDetector**: Analyzes video streams to detect significant moments, using a sensitivity threshold of 0.2 and a maximum time interval of 15 seconds between key frames.
- **GeminiVision**: Processes audio and video inputs to generate insightful poker commentary, guided by a detailed system prompt. It operates with a response temperature of 0.9 and maintains a chat history for context.
- **TokenAggregator**: Aggregates tokens from GeminiVision to form coherent responses.
- **ElevenLabsTTS**: Converts text responses back into spoken audio using Eleven Labs' text-to-speech API, optimized for low latency and using a specific voice model.
- **AudioConverter**: Converts audio formats to ensure compatibility across different services.

#### **Streaming Endpoint**

The `run` method in the `PokerCommentator` class is marked as a streaming endpoint, handling real-time audio and video streams. Here's how it processes these streams:

1. **Audio Processing**: The audio input stream is first converted to text using the `DeepgramSTT` service.
2. **Video Processing**: Simultaneously, the video input stream is analyzed by the `KeyFrameDetector` to identify key moments.
3. **Commentary Generation**: The text from Deepgram and the video analysis from KeyFrameDetector are then processed by `GeminiVision` to generate commentary.
4. **Token Aggregation**: The commentary tokens generated are refined by the `TokenAggregator` for coherence.
5. **Text-to-Speech**: The coherent text is then converted into spoken audio by `ElevenLabsTTS`.
6. **Audio Conversion**: Finally, the audio stream is formatted by the `AudioConverter` for output.

The method outputs three streams: the audio stream of the commentary, the chat history text stream, and the cloned video input stream.

#### **Teardown**

The `teardown` method ensures that all services are properly closed and resources are released when the application is terminated. Each component used in the `setup` and during the streaming endpoint is methodically closed to prevent resource leakage and ensure the application shuts down smoothly.

Deploying with `realtime deploy` hosts it on our serverless backend and allows visual tracking of inputs and outputs via the Realtime dashboard!

## Support

For any assistance or questions, feel free to join our [Discord community](https://discord.gg/cmfFw6SYvp). We're excited to see what you build!