---
title: "Live Sports Commentator"
description: "A realtime commentator that provides live commentary on sports events."
---

<Info>Make sure you have gone over [QuickStart](/examples/quickstart) before trying this example.</Info>

In this example, we will build a realtime commentator that provides commentary on a live poker tournament. 
We accomplish by using screenshare to capture the live game on Youtube and microphone audio to interact with the commentator.

## Demo

<iframe width="560" height="315" src="https://www.youtube.com/embed/WJaYLcX1o7E?si=hNvJwHWbNAXQCsck" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## **Creating a Poker Commentator in 3 steps**

This app will process input from your microphone, video from screenshare, send it to an LLM and convert the reponse back to voice.

- The full github repository is available [here.](https://github.com/xAlpha8/realtime-examples)

<Info>This application will initially support only English as the source language.</Info>

<Steps>
  <Step title="Start by cloning the repository">
    ```bash
    git clone https://github.com/xAlpha8/realtime-examples.git
    ```
    ```bash
    cd realtime-examples/
    ```
    ```bash
    poetry install
    ```

  </Step>
  <Step title="Deploy to Realtime">
    <Warning>Ensure you're in the same directory as poker_commentator.py!</Warning>
    We will use our realtime [Python SDK](/python_client) to deploy our application.

    ```bash
    cd ./multimodal_ai_demos/backend/
    ```
    ```bash
    poetry shell #Activate the python environment
    ```
    ```bash
    realtime deploy --api-key=<your-api-key> poker_commentator.py
    ```

    Your build will complete in seconds, and then you'll receive a link to your deployed function on the Realtime server. Copy the link.
    
    (Coming soon) You can also go to your app on the [Realtime dashboard](https://www.getadapt.ai/dashboard) and get the link.
  </Step>
  <Step title="Launch the frontend">
    We have already created a simple frontend using our [React SDK](/javascript).

    Change directory to the frontend directory.

    ```bash
    cd ../frontend/
    ```

    Change the url in .env file to the link of your deployed function.
    ```bash
    VITE_BACKEND_URL=<your_deployed_function_url>
    ```

    Install the dependencies and run the frontend.
    ```bash
    npm install
    ```
    ```bash
    npm run dev
    ```

    This will launch a simple frontend to interact with the backend.
    You can then browse to the following page with your browser:

    http://127.0.0.1:5173

    Once you select the appropriate option to send audio and/or video, click `Start`.

  </Step>
</Steps>

## **Understanding the Process**

Review the code in `poker_commentator.py`.

#### **Setup**

The `PokerCommentator` class initializes with the `setup` method, which is automatically called when the application starts. This method is responsible for setting up the necessary services and loading models. Here's a breakdown of the services initialized:

- **DeepgramSTT**: Converts spoken audio to text using Deepgram's speech-to-text API, configured with a sample rate of 8000 Hz.
- **KeyFrameDetector**: Analyzes video streams to detect significant moments, using a sensitivity threshold of 0.2 and a maximum time interval of 15 seconds between key frames.
- **GeminiVision**: Processes audio and video inputs to generate insightful poker commentary, guided by a detailed system prompt. It operates with a response temperature of 0.9 and maintains a chat history for context.
- **TokenAggregator**: Aggregates tokens from GeminiVision to form coherent responses.
- **ElevenLabsTTS**: Converts text responses back into spoken audio using Eleven Labs' text-to-speech API, optimized for low latency and using a specific voice model.
- **AudioConverter**: Converts audio formats to ensure compatibility across different services.

#### **Streaming Endpoint**

The `run` method in the `PokerCommentator` class is marked as a streaming endpoint, handling real-time audio and video streams. Here's how it processes these streams:

1. **Audio Processing**: The audio input stream is first converted to text using the `DeepgramSTT` service.
2. **Video Processing**: Simultaneously, the video input stream is analyzed by the `KeyFrameDetector` to identify key moments.
3. **Commentary Generation**: The text from Deepgram and the video analysis from KeyFrameDetector are then processed by `GeminiVision` to generate commentary.
4. **Token Aggregation**: The commentary tokens generated are refined by the `TokenAggregator` for coherence.
5. **Text-to-Speech**: The coherent text is then converted into spoken audio by `ElevenLabsTTS`.
6. **Audio Conversion**: Finally, the audio stream is formatted by the `AudioConverter` for output.

The method outputs three streams: the audio stream of the commentary, the chat history text stream, and the cloned video input stream.

#### **Teardown**

The `teardown` method ensures that all services are properly closed and resources are released when the application is terminated. Each component used in the `setup` and during the streaming endpoint is methodically closed to prevent resource leakage and ensure the application shuts down smoothly.

Deploying with `realtime deploy` hosts it on our serverless backend and allows visual tracking of inputs and outputs via the Realtime dashboard!

## Support

For any assistance or questions, feel free to join our [Discord community](https://discord.gg/cmfFw6SYvp). We're excited to see what you build!
