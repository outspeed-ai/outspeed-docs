---
title: "OpenAI Realtime API (Python)"
description: "A realtime voice bot that uses OpenAI Realtime API in Python."
---

<Info>
  Make sure you have gone over [QuickStart](/examples/quickstart) before trying
  this example.
</Info>

In this example, we will build a realtime voice bot that uses OpenAI Realtime API.
We accomplish this by using microphone audio to interact with the bot.

## Demo

Coming soon

## **Creating a Voice Bot in 4 Steps**

This app will process input from your microphone, send it to an LLM, and convert the response back to voice.

- The full GitHub repository is available [here.](https://github.com/outspeed-ai/outspeed.git)


<Steps>
  <Step title="Start by cloning the repository">

    ```bash
    git clone https://github.com/outspeed-ai/outspeed.git
    cd examples/openai_realtime/
    ```

  </Step>

import InstallOutspeedSnippet from "/snippets/install-outspeed.mdx";
  
  <Step title="Install Dependencies">
    <InstallOutspeedSnippet />
  </Step>

  <Step title="Run Backend">
    <Warning>
      Ensure you’re in the same directory as voice_bot.py!
    </Warning>

    <Tabs>

    <Tab title="Local Server">
      You will need the following environment variables:

      1. `OPENAI_API_KEY` - You can get this by visiting the [OpenAI Realtime API documentation](https://platform.openai.com/docs/guides/realtime) and navigating to the API keys section to generate a new key.

      Once you have your keys, run the following command:

      ```bash
      export OPENAI_API_KEY=<your_openai_api_key>
      ```

      Finally, run the following command to start the server:

      ```bash
      python voice_bot.py
      ```

      The console will output the URL you can use to connect to the server (default is http://localhost:8080).

    </Tab>

    <Tab title="Outspeed Cloud">
      <Info>
        Make sure you have obtained an Outspeed API key before running this example. To
        obtain an API key [Contact us](mailto:contact@outspeed.com)
      </Info>
      We will use our outspeed [Python SDK](https://github.com/outspeed-ai/outspeed.git) to deploy our application.

      ```bash
      outspeed deploy --api-key=<your-api-key> voice_bot.py
      ```

      Your build will complete in seconds, and then you’ll receive a link to your deployed function on the Outspeed server. Copy the link.

      (Coming soon) You can also go to your app on the Outspeed dashboard and get the link.

    </Tab>

    </Tabs>

  </Step>
  <Step title="Run Demo">
    We have already created a simple frontend using our [React SDK](/javascript/introduction).

  1. Open the [Playground](https://playground.outspeed.com/webrtc_input).
  2. Paste the link you received from the previous step into the URL field.
  3. Select your Audio device. Click Run to begin.

  </Step>
</Steps>

## **Understanding the Process**

Review the code in `voice_bot.py`.

#### **Setup**

The `VoiceBot` class initializes with the `setup` method, which is automatically called when the application starts. This method is responsible for setting up the necessary services and loading models. Here's a breakdown of the services initialized:

- **OpenAIRealtime**: Processes audio and text inputs to generate insightful commentary using OpenAI's Realtime API, guided by a detailed system prompt. It operates with a response temperature of 0.9 and maintains a chat history for context.

#### **Streaming Endpoint**

The `run` method in the `VoiceBot` class is marked as a streaming endpoint, handling real-time audio and text streams.

The method outputs two streams: the audio stream of the commentary and the chat history text stream.

## Support

For any assistance or questions, feel free to join our [Discord community](https://discord.gg/cmfFw6SYvp). We're excited to see what you build!