---
title: "Quickstart"
description: "The fastest way to integrate realtime AI into your projects."
---

## What is Realtime?

Realtime is a cutting-edge platform designed to facilitate the discovery, design, and implementation of AI features at scale. 

Features include:

- Ability to create complex applications using multiple models with minimal coding
- Scalable, reliable infrastructure that adjusts based on traffic
- Advanced distributed mechanisms such as queues and asynchronous jobs for efficient data handling

## **Getting Started**
 
- [Sign up](https://www.getadapt.ai/dashboard) and obtain your [API key](https://www.getadapt.ai/dashboard/settings)
- Install the Realtime Python client
```bash
pip install realtime-client
```
{
  /*
  - Authenticate with your API key
  ```bash
  realtime login
  ```
  */
}

### **Creating a basic Voice Chatbot app**

Here's how to develop a straightforward Voice Chatbot application on Realtime. 
This app will process input from your microphone, send it to an LLM and convert that text to voice.

- The full github repository is available [here.](https://github.com/xAlpha8/realtime-client)

<Info>This application will initially support only English as the source language.</Info>

<Steps>
  <Step title="Start by creating a new directory and file">
    ```bash
    git clone https://github.com/xAlpha8/realtime-client && cd realtime-client/examples/voice_bot/
    ```

    Review the following code in `voice_bot.py`:
    ```python
      import asyncio
      import os

      import realtime
      from realtime.plugins import DeepgramSTTService, ElevenLabsTTSService, OpenAILLMService


      @realtime.streaming_endpoint()
      async def voice_bot(audio_input_queue, video_input_queue):
          stt = DeepgramSTTService(api_key=os.environ.get("DEEPGRAM_API_KEY"), sample_rate=8000)
          llm = OpenAILLMService(
              api_key=os.environ.get("OPENAI_API_KEY"),
          )
          tts = ElevenLabsTTSService(api_key=os.environ.get("ELEVEN_LABS_API_KEY"))
          dq = await stt.arun(audio_input_queue)
          lq = await llm.arun(dq)
          eq = await tts.arun(lq)
          return eq, None


      if __name__ == "__main__":
          asyncio.run(voice_bot())
  ```
  </Step>
  <Step title="Deploy to Realtime">
    <Warning>Ensure you're in the same directory as voice_bot.py!</Warning>
    ```bash
    realtime deploy voice_bot.py
    ```

    Your build will complete in seconds, and then you'll receive a link to your deployed function on the Realtime dashboard.
    You can also go to your app on the [Realtime dashboard](https://www.getadapt.ai/dashboard) and get the link.
  </Step>
  <Step title="Launch the frontend">

    There is a server.py file in the same directory as main.py that will launch a basic HTML and Javascript frontend that will connect 
    to the serverless instance you deployed via WebRTC.

    <Info>Replace ```{insert_link}``` with the link received after realtime deploy.</Info>
    In another terminal, run:
    ```bash
    python server.py --backend {insert_link}
    ```
    You can then browse to the following page with your browser:

    http://127.0.0.1:8080

    Once you click `Start` the browser will send the audio and video from its
    webcam to the server.

  </Step>
</Steps>

### **Understanding the Process**

Creating this simple voice AI app was straightforward! The core of our application relied on three Realtime plugins:
- [realtime.plugins.DeepgramSTTService](): A transcription model powered by Deepgram.
- [realtime.plugins.OpenAILLMService](): A LLM model developed by OpenAI.
- [realtime.plugins.ElevenLabsTTSService](): A text-to-speech model developed by Eleven Labs.

We encapsulated all translation logic in a single function and defined it as a realtime function using the [`@realtime.streaming_endpoint`](/python_client/sdk/streaming_endpoint) decorator.

Deploying with `realtime deploy` hosts it on our serverless backend and allows visual tracking of inputs and outputs via the Realtime dashboard!

## **Next Steps**

To start using Realtime, create an [account](https://www.getadapt.ai/dashboard). You can then explore further applications and capabilities.

<CardGroup cols={3}>
  <Card 
  title="Gym/Fitness Trainer"
  href="gym"
  icon="image"
  color="#ea5a0c"
  >
    A live fitness coach with video understanding
  </Card>
  <Card 
  title="Cooking Assistant" 
  href="cooking"
  icon="image"
  color="#ea5a0c"
  >
    Cooking assistant that guides you through the process of preparing a meal
  </Card>
  <Card 
  title="Sports Commentary" 
  icon="image"
  color="#ea5a0c"
  href="commentary"
  >
    Live Sports Commentary
  </Card>
</CardGroup>

## Support

For any assistance or questions, feel free to join our [Discord community](https://discord.gg/cmfFw6SYvp). We're excited to see what you build!
