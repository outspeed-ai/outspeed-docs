---
title: "Overview"
description: "Build low-latency conversational applications on Outspeed's voice stack"
---

# Introduction

Outspeed powers voice companions and agents by providing natural, emotive voice with memory.
It's like having thousands of digital humans that can hold natural-sounding conversations with emotions, remember things, and carry out tasks on a computer.

Outspeed provides streaming API endpoints and SDKs that companies, developers, and individuals
can use to embed voice companions and agents in their applications.

We offer an **OpenAI Realtime API compatible interface** to interact with Outspeed's voice stack.

## Explore

<CardGroup cols={2}>
  <Card
    title="Playground"
    icon="microphone"
    href="https://dashboard.outspeed.com"
  >
    Playground to test out Outspeed's voice stack with different prompts and voices.
  </Card>
  <Card
    title="Live API"
    icon="bolt"
    href="/api-spec/live-api"
  >
    Build and deploy low-latency voice experiences with the Outspeed Live API.
  </Card>
  <Card
    title="Build a Mobile App"
    icon="mobile"
    href="/iOS/outspeed-swift-getting-started"
  >
    Get started building iOS apps with realtime voice using the Outspeed Swift SDK.
  </Card>
  <Card
    title="Build a Web App"
    icon="browser"
    href="/react/setup"
  >
    Get started building react apps with realtime voice using the Outspeed React SDK.
  </Card>
</CardGroup>

## What Outspeed Offers

Outspeed specializes in enabling low-latency, realtime, voice-driven interactions with the following capabilities:

- **Natural Emotive Voice**: AI companions and agents capable of expressing emotions (e.g., laugh, cry) through voice.
- **Memory & Context Management**: Agents can remember information from conversations and manage context effectively.
- **Task Execution**: Perform tasks via LLM function calling, integrating with external tools and services.
- **Customizable Voices**: Options for custom or cloned voices, allowing agents to sound unique.
- **Multi-model Support**: Access to leading speech models, including our core stack:
    -   **LLM:** Llama-4 for advanced understanding and reasoning.
    -   **VAD:** Specialized system for rapid voice activity detection (semantic VAD for improved accuracy).
    -   **Transcription:** "Outspeed Whisper" (fast Whisper) for quick, accurate speech-to-text as part of the conversational flow.
    -   **TTS:** Fast Orpheus-3B for natural and emotive voice output.
- **Developer-friendly Tools**: Comprehensive APIs (including the Live API) and testing environments like Voice DevTools.

