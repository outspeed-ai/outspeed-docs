---
title: "Introduction"
description: "Quickly build realtime AI applications using OutspeedSDK"
---

## What is Adapt?

Adapt allows you to quickly build realtime AI applications on video and voice.

You can build applications like:

1. Interactive voice bot for information collection, customer support, therapy, companionship, etc.
2. AI avatar for gaming, sales, marketing, etc.
3. Physical security for theft detection, permiter protection, etc.
4. Video intelligence systems for object search, OCR, action detection, etc.

To write your application backend, use `outspeed` PythonSDK that's purpose built for voice and video apps.
The frontend components are available in `realtime-react` npm package and help you integrate with the deployed backend easily.

## Introduction to `outspeed` Python SDK

Adapt's Python SDK provides a powerful and flexible way to build realtime AI applications on top of video, voice, and text data. With this SDK, you can easily create interactive voice bots, AI avatars, physical security systems, and video intelligence applications.

### Key Features

1. **Realtime Processing**: Handle streaming data for audio, video, and text in real-time.

2. **Easy Integration**: Seamlessly integrate with various AI services and models.

3. **Serverless Deployment**: Deploy your applications with a single command to our serverless infrastructure.

4. **Flexible Architecture**: Build complex applications using a modular approach.

## Getting Started

### Installation

To get started with Adapt's Python SDK, you'll need Python 3.9 or later. Install the SDK using pip:

import InstallOutspeedSnippet from "/snippets/install-outspeed.mdx";
  
<InstallOutspeedSnippet />

### Basic Usage

Here's the scaffolding for a realtime application built using Adapt's Python SDK:

```python
import outspeed as sp

@rt.App()
class MyApplication:
    def setup(self):
        # Initialize your services, databases and models
        pass

    @rt.streaming_endpoint()
    async def run(self, video_input: rt.VideoStream) -> rt.VideoStream:
        # Process the video stream
        pass

    def teardown(self):
        # Clean up resources
        pass

```

This demonstrates the basic structure of an Adapt application:

1. We use the `@rt.App()` decorator to define our application class.
2. The `setup` method is used to initialize services and load models.
3. The `run` method is decorated with `@rt.streaming_endpoint()` to handle realtime streaming data.
4. The `teardown` method is used for cleaning up resources when the application stops.

## Core Concepts

1. **`rt.App`**: The main application class that encapsulates your entire application logic. This is what's deployed on Adapt cloud and scales based on the number of concurrent connections
   to the endpoint.

2. **Endpoint**: In this scafolding, we use a `rt.streaming_endpoint()` which is a WebRTC endpoints. You can learn about other types of endpoints [here](). WIP.

3. **Streams**: A streaming endpoint can accept multiple types of streams. The supported stream types are: `TextStream`, `AudioStream`, `VideoStream`, and `ByteStream`. Currently, you can only have one argument of each stream type in your endpoint function. Adapt's infrastructure handles the streams on the frontend and connects them to your realtime application python code. You can read more about stream types [here](). (Note: This section is a work in progress.)

## Deployment

Once you've built your application, you can deploy it to Adapt's serverless infrastructure using the CLI:

<Info>
  You need to have `outspeed` python package installed for this CLI command.
</Info>

```bash
export ADAPT_API_KEY=<your-api-key>
outspeed deploy --api-key=$ADAPT_API_KEY your_app_file.py
```
