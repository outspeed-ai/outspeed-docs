---
title: "Quick Start Voice Bot"
description: "Outspeed is a cutting-edge platform designed to facilitate the design and implementation of multi-modal AI features at scale."
---

## What is Outspeed?

Outspeed is a cutting-edge platform designed to facilitate the design and implementation of multi-modal AI features at scale.

Features include:

- Ability to create complex applications using multiple AI models with minimal coding.
- Scalable, reliable serverless infrastructure that adjusts based on traffic

## Demo

Here's a short demo of what the voice bot looks like:

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/32HnQDZ3Jfk?si=E24k_zNrufSQ9RPk"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  referrerpolicy="strict-origin-when-cross-origin"
  allowfullscreen
></iframe>

## **Getting Started**

<Info>
  Make sure you have obtained an Adapt API key before running this example. To
  obtain an API key [Contact us](mailto:contact@getadapt.ai)
</Info>

### **Creating a Voice Bot in 3 steps!**

This app will process input from your microphone, send it to an LLM and convert the reponse back to voice.

<Info>
  This application will initially support only English as the source language.
</Info>

<Steps>
  <Step title="Start by cloning the repository">

    ```bash
    git clone https://github.com/xAlpha8/realtime-examples.git
    cd realtime-examples/
    ```
    Using Poetry:
    ```bash
    git clone https://github.com/xAlpha8/realtime-examples.git
    cd realtime-examples/
    ```
    Using Pip:
    ```bash
    git clone https://github.com/xAlpha8/realtime-examples.git
    cd realtime-examples/
    ```

  </Step>
  <Step title="Deploy to Outspeed">
  <Warning>
  Ensure you’re in the same directory as voice_bot.py!
</Warning>
    We will use our outspeed [Python SDK](/python_client) to deploy our application.

```bash
git clone https://github.com/xAlpha8/realtime-examples.git
cd realtime-examples/
```

Your build will complete in seconds, and then you’ll receive a link to your deployed function on the Outspeed server. Copy the link.

(Coming soon) You can also go to your app on the Outspeed dashboard and get the link.

  </Step>
  <Step title="Launch Front-End">
  We have already created a simple frontend using our [React SDK](/react_client).

Change directory to the frontend directory.

      ```bash
    git clone https://github.com/xAlpha8/realtime-examples.git
    cd realtime-examples/
    ```
    Install the dependencies and run the frontend.
    ```bash
    npm install
    cd ./multimodal_ai_demos/backend/
    ```
    ```bash
    npm run dev
    cd ./multimodal_ai_demos/backend/
    ```

    This will launch a simple frontend to interact with the backend. You can then browse to the following page with your browser:

    http://127.0.0.1:5173

Select Audio and Video and Click Start to begin.

  </Step>
</Steps>

### Next Steps

You can explore further applications and capabilities here:

<Info>
  Make sure you have obtained an Adapt API key before running this example. To
  obtain an API key [Contact us](mailto:contact@getadapt.ai)
</Info>

## Support

For any assistance or questions, feel free to join our [Discord community](https://discord.gg/cmfFw6SYvp). We’re excited to see what you build!
