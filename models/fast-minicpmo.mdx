---
title: "Fast MiniCPM-o"
description: "An 8B parameter model for realtime speech and text streaming."
---

Fast MiniCPM-o is a powerful multimodal model optimized and hosted by Outspeed.
It has 2.5x lower inference latency than the base MiniCPM-o model built by ModelBest.

You can play around with thi model using [Voice Devtools](/get-started/voice-devtools) or 
use it in your apps using [Outspeed Live API](/api-spec/live-api).

It supports:

- Vision and speech understanding
- Real-time speech conversation
- Multimodal live streaming
- Voice customization and cloning
- End-to-end speech modeling

The model achieves comparable performance to GPT-4 in vision, speech and multimodal tasks while being optimized for efficient deployment on end devices.

For more details about the base model, visit the [MiniCPM-o repository](https://github.com/OpenBMB/MiniCPM-o). 